[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A524.04.2-23aa62.svg)](https://www.nextflow.io/)
[![run with conda](http://img.shields.io/badge/run%20with-conda-3EB049?labelColor=000000&logo=anaconda)](https://docs.conda.io/en/latest/)
[![run with docker](https://img.shields.io/badge/run%20with-docker-0db7ed?labelColor=000000&logo=docker)](https://www.docker.com/)
[![run with singularity](https://img.shields.io/badge/run%20with-singularity-1d355c.svg?labelColor=000000)](https://sylabs.io/docs/)

## Introduction

This workflow is designed to compute [quality metrics as required by BfArM](https://www.bfarm.de/SharedDocs/Downloads/DE/Forschung/modellvorhaben-genomsequenzierung/Qs-durch-GRZ.pdf?__blob=publicationFile) for **genome data centers (Genomrechenzentren, GRZs)** and serves as a **reference implementation** for all **Leistungserbringer (LEs)**.

> [!IMPORTANT]
>
> - Leistungserbringer are not required to use this specific workflow to calculate metrics. Any method that produces reasonably matching results can be used. This workflow will be used by the GRZ's to validate the reported metrics.
> - Please note that we are neither permitted nor able to provide direct support for running this QC workflow in hospitals.
> - Features such as running on pre-mapped reads are not part of the official requirements, but are offered as helpful additions for LEs when feasible.
> - We greatly appreciate collaboration and encourage contributions to help improve the workflow.

This workflow is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

1. Read QC ([`FastQC`](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) and [`FASTP`](https://github.com/OpenGene/fastp))
2. Alignment using [`BWAMEM2`](https://github.com/bwa-mem2/bwa-mem2)
3. MarkDuplicates using [`Picard`](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard)
4. Coverage calculation by [`Mosdepth`](https://github.com/brentp/mosdepth)
5. Present QC for raw reads ([`MultiQC`](http://multiqc.info/))

Details on the coverage calculation of different library types can be found in the [documentation](docs/details.md).

For the exact command lines executed by the pipeline you may check the workflow reports automatically generated by the test pipeline on GitHub.
To access these reports, click on the title of the latest successful [pipeline run](https://github.com/BfArM-MVH/GRZ_QC_Workflow/actions/workflows/tests.yml) and download the `nextflow-pipeline-info` artifact under the "Artifacts" section at the bottom of the page.
The command lines are detailed the the "Tasks" table at the bottom of the `execution_report_*.html` file.

## Setup

- Install nextflow (and dependencies)
- Make sure to have either conda, docker or singularity.
- Clone the github repository

```bash
git clone https://github.com/BfArM-MVH/GRZ_QC_Workflow.git
```

## Usage

This pipeline needs one of the following two inputs:

1. A submission base directory path with a folder structure following [GRZ submission standard](https://github.com/BfArM-MVH/grz-cli?tab=readme-ov-file#introduction). You can also check [test datasets](https://www.cmm.in.tum.de/public/grz-example-submissions/).

2. Use a csv samplesheet as input. This gives more flexibilty, as you don't need a GRZ submission directory.

Here are the instructions for the case (1). For (2) please see the [documentation](docs/usage.md#samplesheet-input).

You can run the pipeline with flag `--submission`:

```bash
submission_basepath="path/to/submission/base/directory"
nextflow run main.nf \
    -profile docker \
    --outdir "path/to/output/directory/" \
    --submission "${submission_basepath}"
```

You may change profile from `docker` to `conda`, `singularity`, or `podman`, depending on which environment management software you prefer to use.
We regularly test `docker` and `conda`.

Depending on the resouces on your machine and your task, it is recommended to create and and run with your own config file, see [estimated resource requirements for WGS](#estimated-resource-requirements) and [nextflow documentation](https://nf-co.re/docs/usage/getting_started/configuration#custom-configuration-files).

## Caching reference files

With the above code, the pipeline will automatically download the necessary reference genomes and create BWA-MEM2 indices from them.
However, when running this pipeline multiple times on different submissions, repeatedly downloading and indexing the same reference genomes is a waste of resources.

Therefore, **it is recommended** to use `--reference_path` to specify a directory to cache reference genomes and their indicies between pipeline runs to save resources.

A more detailed description of reference files usage can be found [here](docs/usage.md#reference-files).

## Pipeline output

Output :

| Column                                      | Description                                                             |
| ------------------------------------------- | ----------------------------------------------------------------------- |
| `sampleId`                                  | Sample ID                                                               |
| `labDataName`                               | Lab data name                                                           |
| `libraryType`                               | Library type, e.g., `wes` for whole-exome sequencing                    |
| `sequenceSubtype`                           | Sequence subtype, e.g., `somatic` or `germline`                         |
| `genomicStudySubtype`                       | Genomic study subtype, e.g., `tumor+germline`                           |
| `meanDepthOfCoverage`                       | Mean depth of coverage                                                  |
| `meanDepthOfCoverageRequired`               | Mean depth of coverage required to pass QC                              |
| `percentBasesAboveQualityThreshold`         | Percent of bases passing the quality threshold                          |
| `qualityThreshold`                          | The quality threshold to pass                                           |
| `percentBasesAboveQualityThresholdRequired` | Percent of bases above the quality threshold required to pass QC        |
| `targetedRegionsAboveMinCoverage`           | Fraction of targeted regions above minimum coverage                     |
| `minCoverage`                               | Minimum coverage for target regions                                     |
| `targetedRegionsAboveMinCoverageRequired`   | Fraction of targeted regions above minimum coverage required to pass QC |
| `passedQC`                                  | `true` when QC passed, otherwise `false`                                |

For more details about the output files and reports, please refer to the [output documentation](docs/output.md).

## Thresholds

QC thresholds are read from [`thresholds.json`](https://github.com/BfArM-MVH/GRZ_QC_Workflow/blob/main/assets/default_files/thresholds.json), which uses the values [defined by BfArM](https://www.bfarm.de/SharedDocs/Downloads/DE/Forschung/modellvorhaben-genomsequenzierung/Qs-durch-GRZ.pdf?__blob=publicationFile).

## Running the pipeline offline

Nextflow can automatically retrieve almost everything necessary to execute a pipeline from the web, including pipeline code, software dependencies, reference genomes, and remote data sources.

However, if your analysis must run on a system without _internet access_, you will need to take a few additional steps to ensure all required components are available locally. First, download everything on an internet-connected system (such as your personal computer) and then transfer the files to the offline system using your preferred method.

To set up an offline environment, you will need three key components: a functioning Nextflow installation, the pipeline assets, and the required reference genomes.

On a computer with an internet connection, to download the pipeline, run:

```bash
nf-core pipelines download BfArM-MVH/GRZ_QC_Workflow
```

Add the argument `--container-system singularity` to also fetch the singularity container(s).

Then download the necessary plugins and lace it under `${NXF_HOME}/plugins`:

```bash
nextflow plugin install nf-schema@2.1.1

```

For more detailed information please check ["Running offline by nf-core"](https://nf-co.re/docs/usage/getting_started/offline)

## Estimated resource requirements

Using the 466 GB `WGS_tumor+germline` test submission dataset from the
[example GRZ submissions](https://www.cmm.in.tum.de/public/grz-example-submissions),
the pipeline used the following resources:

- 828 CPU hours
- 72 GB maximum RAM (genome indexing)
- 2 TB storage (including the input files)

The biggest jobs were the two bwa-mem2 alignments which used 300 CPU hours each
and a maximum of 48 GB of RAM.

## Contributions and Support

**BfArM-MVH/GRZ_QC_Workflow** was originally written by Yun Wang, Kübra Narci, Shounak Chakraborty and Florian R. Hölzlwimmer.
